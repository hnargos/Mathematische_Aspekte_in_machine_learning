{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical Aspects of Machine Learning: Exercise Sheet 1\n",
    "by Henrik Narvaez, Marvin Rominger, Johannes von Lindheim und Luzie Helfmann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exercise 1 (a) <br> \n",
    "We created $100$ random data points in $2$ dimensions. This is just one example to see how the algorithm works before using it on differet $l$ and $n$. <br>\n",
    "A label $+1$ (set A) or $-1$ (set B) is assigned to each data point. The points are linearly seperable (and thus also absolutely linearly seperable as we have a finite training set) because they were split into two groups by creating a random vector $w$ such that $$ w^Tx\\geq \\theta$$ or $$w^Tx<\\theta$$ for all $x$ in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_plot(fig, ax, xmin, ymin, xmax, ymax):\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xlabel(r\"$x$\")\n",
    "    ax.set_ylabel(r\"$y$\")\n",
    "    ax.set_aspect('equal')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l=10\n",
    "#dimension \n",
    "n=2 \n",
    "\n",
    "trainingdata=np.random.rand(l,n+1) #random data points in (0,1)^n\n",
    "trainingdata[:,-1]=np.ones((1,l)) #n+1'th dimension to account for theta\n",
    "\n",
    "#assign labels to training data such that they are linearly seperable           \n",
    "wrandom=np.random.rand(n)\n",
    "datalabels=np.zeros(l)\n",
    "theta=np.dot(wrandom,trainingdata[1,:n])\n",
    "for i in range(l):\n",
    "    if np.dot(wrandom,trainingdata[i,:n])>=theta:\n",
    "        datalabels[i]=1\n",
    "    else:\n",
    "        datalabels[i]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (trainingdata, datalabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the data in the example below, the training data points with label $+1$ are shown as red circles, the points with label $-1$ are shown as blue stars. And the two sets are seperated by the line wrandom (with the Perceptron algorithm we want to find such a seperating line).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x=np.linspace(0,1,num=l)\n",
    "y=np.zeros(l)\n",
    "for i in range(10):\n",
    "    y[i]=(theta-wrandom[0]*x[i])/wrandom[1]\n",
    "\n",
    "index1=[i for i,e in enumerate(datalabels) if e==1]\n",
    "indexmin1=[i for i,d in enumerate(datalabels) if d==-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plt.plot(trainingdata[index1,0],trainingdata[index1,1],'ro')\n",
    "plt.plot(trainingdata[indexmin1,0],trainingdata[indexmin1,1],'b*')\n",
    "plt.plot(x,y)\n",
    "format_plot(fig, ax, 0, 0, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Perceptron algorithm we iterate and cycle through all the training data points until we find a $w_t$ such that all points in one set are on one side of the hyperplane and all the others on the other side. As a maximum number of iterations we have set $1000$ and the stopping criteria is that the algorithm has cycled through all training points without having to adjust weight vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#perceptron algorithm\n",
    "t=0\n",
    "w=np.random.rand(n+1) #n+1 dimensional to account for theta \n",
    "cycle=0 #to keep track of whether we cycled through all training data points\n",
    "\n",
    "for t in range(1000):\n",
    "    for i in range(l):\n",
    "        if datalabels[i]==np.sign(np.dot(w,trainingdata[i,:])):\n",
    "            cycle+=1\n",
    "        else:\n",
    "            w += datalabels[i] * trainingdata[i, :]\n",
    "            cycle = 0\n",
    "            break\n",
    "    if cycle==l: #stopping criteria\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=np.linspace(0,1,num=l)\n",
    "for i in range(10):\n",
    "    y[i]=(-w[2]-w[0]*x[i])/w[1]\n",
    "\n",
    "index1=[i for i,e in enumerate(datalabels) if e==1]\n",
    "indexmin1=[i for i,d in enumerate(datalabels) if d==-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plt.plot(trainingdata[index1,0],trainingdata[index1,1],'ro')\n",
    "plt.plot(trainingdata[indexmin1,0],trainingdata[indexmin1,1],'b*')\n",
    "plt.plot(x,y)\n",
    "format_plot(fig, ax, 0, 0, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test our algorithm on different $n$ (dimensions) and $l$ (number of training data). And see how and compare how the algorithm behaves in terms of number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#setting parameters\n",
    "maxn=10 #maximum number of dimensions\n",
    "maxl=100 #maximum number of training elements\n",
    "repetitions=100 #number of repetitions to estimate the number of iterations for certain n and l\n",
    "\n",
    "iterations=np.zeros((3,maxl -1,maxn -1))\n",
    "iterations[0,:,:]=np.array([range(2,maxn+1) for k in range(1,maxl)])\n",
    "iterations[1,:,:]=np.array([range(2,maxl+1) for k in range(1,maxn)]).T\n",
    "     \n",
    "for n in range(2,maxn + 1): #dimension \n",
    "    for l in range(2,maxl + 1): #size of training data set\n",
    "        tmean=0\n",
    "        for k in range(repetitions):\n",
    "            trainingdata=np.random.rand(l,n+1) #random data points\n",
    "            trainingdata[:,-1]=np.ones((1,l)) #n+1 dimensional to account for theta\n",
    "            \n",
    "            #create random linearly seperable training data             \n",
    "            wrandom=np.random.rand(n)\n",
    "            datalabels=np.zeros(l)\n",
    "            theta=np.dot(wrandom,trainingdata[1,:n])\n",
    "            for i in range(l):\n",
    "                if np.dot(wrandom,trainingdata[i,:n])>=theta:\n",
    "                    datalabels[i]=1\n",
    "                else:\n",
    "                    datalabels[i]=-1\n",
    "                 \n",
    "            #linearly seperable test data of dimension n\n",
    "            #even absolutely linearly separable as the two sets A and B are finite\n",
    "            \n",
    "            \n",
    "            #perceptron algorithm\n",
    "            w=np.random.rand(n+1) #n+1 dimensional to account for theta \n",
    "            cycle=0 #to keep track of whether we cycled through all training data points\n",
    "                 \n",
    "                \n",
    "            for t in range(1,500):\n",
    "                for i in range(l):\n",
    "                    if datalabels[i]==np.sign(np.dot(w,trainingdata[i,:])):\n",
    "                    #sign can also be 0 !!!\n",
    "                        cycle+=1\n",
    "                    elif datalabels[i]==1:\n",
    "                        w+=trainingdata[i,:]\n",
    "                        cycle=0\n",
    "                        break\n",
    "                    else:\n",
    "                        w-=trainingdata[i,:]\n",
    "                        cycle=0\n",
    "                        break      \n",
    "                if cycle==l: #stopping criteria\n",
    "                    tmean+=1./repetitions*t\n",
    "                    break\n",
    "                    \n",
    "        iterations[2,l-2,n-2]=tmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(maxl-1):     \n",
    "    plt.plot(iterations[0,i,:],iterations[2,i,:],'ro')\n",
    "    plt.title('training data points l = '+str(i+2))\n",
    "    plt.ylabel('average number of iterations' + str(repetitions) +  ' repetions')\n",
    "    plt.xlabel('dimension n')\n",
    "for i in range(maxn-1):     \n",
    "    plt.plot(iterations[1,:,i],iterations[2,:,i],'bo')\n",
    "    plt.ylabel('average number of iterations ' + str(repetitions) +  ' repetions')\n",
    "    plt.title('dimension n = '+ str(i+2))\n",
    "    plt.xlabel('number of training data points l')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in conclusion, for a fixed number of training data points, the number of iterations decreases with increasing dimension (seems to fall exponentially); and for a fixed dimension of the space, the number of iterations seems to increase (linearly) with increasing number of data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 (b) <br>\n",
    "Next we want to find an example for which the algorithm takes very very long to find the weight vector which seperates the two sets A and B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l=5 \n",
    "n=5 \n",
    "trainingdata=np.array([[-0.93652338, -0.90652662, -0.9842292 , -0.91720455, -0.94420967,\n",
    "         1.        ],\n",
    "       [ 1.01724911,  1.04598597,  1.04287103,  1.05005195,  1.01763736,\n",
    "         1.        ],\n",
    "       [ 1.04302792,  1.01471629,  1.02017942,  1.04279241,  1.04448992,\n",
    "         1.        ],\n",
    "       [ 1.07343644,  1.03190436,  1.05094974,  1.0268245 ,  1.0763322 ,\n",
    "         1.        ],\n",
    "       [ 1.06358414,  1.06779813,  1.02946642,  1.07718681,  1.09281483,\n",
    "         1.        ]])\n",
    "   \n",
    "datalabels=np.array([-1.,  1., -1.,  1.,  1.])\n",
    "\n",
    "#plotting the points in 2 dimensions to understand the difficulty of finding a hyperplane\n",
    "index1=[i for i,e in enumerate(datalabels) if e==1]\n",
    "indexmin1=[i for i,d in enumerate(datalabels) if d==-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plt.scatter(trainingdata[index1,0],trainingdata[index1,1],c='r')\n",
    "plt.scatter(trainingdata[indexmin1,0],trainingdata[indexmin1,1],c='b')\n",
    "format_plot(fig, ax, -1.5, -1.5, 1.5, 1.5)\n",
    "\n",
    "print('The plot below shows the vectors in the first two dimensions, the different colours stand for the different labels +1 and -1.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason the perceptron algorithm will take so many iterations when seperating the two sets A and B is that, the data points are very close to another and the distance from the points to the hyperplane will be very small. Also the vectors all point along nearly the same direction, so $w_t$ changes its direction only very slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "               \n",
    "#perceptron algorithm\n",
    "t=0\n",
    "w=np.random.rand(n+1) #n+1 dimensional to account for theta \n",
    "cycle=0 #to keep track of whether we cycled through all training data points\n",
    "     \n",
    "    \n",
    "for t in range(10000):\n",
    "    for i in range(l):\n",
    "        if datalabels[i]==np.sign(np.dot(w,trainingdata[i,:])):\n",
    "        #sign can also be 0 !!!\n",
    "            cycle+=1\n",
    "        elif datalabels[i]==1:\n",
    "            w+=trainingdata[i,:]\n",
    "            cycle=0\n",
    "            break\n",
    "        else:\n",
    "            w-=trainingdata[i,:]\n",
    "            cycle=0\n",
    "            break      \n",
    "    if cycle==l: #stopping criteria\n",
    "        break\n",
    "\n",
    "print('The number of iterations to find the hyperplane seperating the two sets is ' +str(t) +'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 (c) <br>\n",
    "The task was to produce an estimate for the maximum number of vectors one can pick at random and which are supposed to be in the same set (say A) such that all points can be seperated by a hyperplane through the origin (i.e. $\\theta=0$).<br>\n",
    "We estimated (for different values of dimension $n$) for each $l$ (number of training data points) the proportion of runs such that a hyperplane (as described above) exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxn=10\n",
    "maxl=10\n",
    "repetitions=100\n",
    "\n",
    "behaviour=np.zeros((3,maxl-1,maxn-1))\n",
    "behaviour[0,:,:]=np.array([np.arange(2,maxn + 1,1 ) for k in range(maxl-1)])\n",
    "behaviour[1,:,:]=np.array([np.arange(2,maxl + 1,1) for k in range(maxn-1)]).T\n",
    "\n",
    "        \n",
    "for n in np.arange(2,maxn+1,1 ): #dimension \n",
    "    for l in np.arange(2,maxl + 1,1): #size of training data set        \n",
    "        propsep=0\n",
    "        for k in range(repetitions):\n",
    "            trainingdata=np.random.uniform(-1,1,(l,n)) #random data points\n",
    "            datalabels=np.ones(l)\n",
    "            \n",
    "            #perceptron algorithm\n",
    "            w=np.random.rand(n) #n+1 dimensional to account for theta \n",
    "            cycle=0 #to keep track of whether we cycled through all training data points\n",
    "                 \n",
    "                \n",
    "            for t in range(1,5000):\n",
    "                for i in range(l):\n",
    "                    if datalabels[i]==np.sign(np.dot(w,trainingdata[i,:])):\n",
    "                    #sign can also be 0 !!!\n",
    "                        cycle+=1\n",
    "                    elif datalabels[i]==1:\n",
    "                        w+=trainingdata[i,:]\n",
    "                        cycle=0\n",
    "                        break\n",
    "                    else:\n",
    "                        w-=trainingdata[i,:]\n",
    "                        cycle=0\n",
    "                        break      \n",
    "                if cycle==l: #stopping criteria\n",
    "                    propsep+=1./repetitions\n",
    "                    break\n",
    "                    \n",
    "        behaviour[2,l-2,n-2]=propsep\n",
    "\n",
    "row_labels=np.array([str(i) for i in range(2,maxl+1)])\n",
    "column_labels=np.array([str(i) for i in range(2,maxn+1)])\n",
    "print('proportion of runs such that the set was linearly seperable \\ndimension n (columns) vs size of training data set l (rows)')\n",
    "DataFrame(behaviour[2,:,:], row_labels, column_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Excercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is all about the pocket algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test data\n",
    "This data is probably _not_ linearly seperable: After generating an absolutely linearly seperable set, the labels of l_wrong points are switched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_data(n, l, l_wrong):\n",
    "    \"\"\"Generates (possibly non-linear-seperable) data for the pocket algorithm in [0, 1]^n.\n",
    "\n",
    "    Parameters:\n",
    "        n: dimension of data points\n",
    "        l: number of data points\n",
    "        l_wrong: number of data points to put on the wrong side of the seperating hyperplane\n",
    "        \n",
    "    Returns:\n",
    "        trainingdata: generated data points\n",
    "        datalabels: array of +/- 1, labels of training data points\n",
    "        wrandom: hyperplane according to which the data was labeled\n",
    "        theta: see wrandom\n",
    "    \"\"\"\n",
    "\n",
    "    trainingdata = np.random.rand(l,n+1) #random data points in (0,1)^n\n",
    "    trainingdata[:,-1] = np.ones((1,l)) #n+1'th dimension to account for theta\n",
    "\n",
    "    #assign labels to training data such that they are linearly seperable           \n",
    "    wrandom = np.random.rand(n)\n",
    "    theta = np.dot(wrandom, trainingdata[0, :n])\n",
    "    datalabels = np.zeros(l)\n",
    "    datalabels[:] = [1 if np.dot(wrandom, trainingdata[i, :n]) >= theta else -1 for i in range(l)]\n",
    "\n",
    "    # switch the labels of some points\n",
    "    change_inds = random.sample(range(l), l_wrong)\n",
    "    datalabels[change_inds] = -datalabels[change_inds]\n",
    "    \n",
    "    return trainingdata, datalabels, wrandom, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingdata, datalabels, wrandom, theta = generate_data(2, 200, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_line_pts = 2\n",
    "x=np.linspace(0, 1, num=num_line_pts)\n",
    "y=np.zeros(num_line_pts)\n",
    "for i in range(num_line_pts):\n",
    "    y[i]=(theta-wrandom[0]*x[i])/wrandom[1]\n",
    "\n",
    "index1=[i for i,e in enumerate(datalabels) if e==1]\n",
    "indexmin1=[i for i,d in enumerate(datalabels) if d==-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plt.plot(trainingdata[index1,0],trainingdata[index1,1],'ro')\n",
    "plt.plot(trainingdata[indexmin1,0],trainingdata[indexmin1,1],'b*')\n",
    "plt.plot(x,y)\n",
    "format_plot(fig, ax, 0, 0, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pocket Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pocket_algorithm(max_iter, trainingdata, datalabels, verbose=False):\n",
    "    \"\"\"Runs the pocket algorithm.\n",
    "\n",
    "    Parameters:\n",
    "        max_iter: maximum number of iterations to run the algorithm.\n",
    "        trainingdata: data points to classify.\n",
    "        datalabels: array of +/- 1, labels of training data points.\n",
    "        verbose: whether to print some verbose data at the end.\n",
    "        \n",
    "    Returns:\n",
    "        n_correct: number of correctly classified points\n",
    "        ws: stored pocket classifier vector (best classifier when all iterations were run)\n",
    "    \"\"\"\n",
    "    l = trainingdata.shape[0] # number of points\n",
    "    n = trainingdata.shape[1] - 1 # dimension of data points\n",
    "    t = 0 # iteration step\n",
    "    w = np.random.rand(n+1) # n+1 dimensional to account for theta\n",
    "    h = 0 # number of currently correctly classified points\n",
    "    ws = w # stored (pocket) vector\n",
    "    hs = 0 # number of correctly classified points for pocket vector\n",
    "    touched = Series(np.repeat(False, l)) # boolean for every index, if that element was checked\n",
    "    n_correct = 0 # at the end, this tells, how many points are classified correctly by ws\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        \n",
    "        # pick random non-checked element\n",
    "        ind = touched[lambda x: x==False].index[random.randint(0, l-h-1)]\n",
    "\n",
    "        # point correctly classified?\n",
    "        if datalabels[ind] == np.sign(np.dot(w, trainingdata[ind, :])):\n",
    "            touched.iloc[ind] = True\n",
    "            h += 1\n",
    "        else:\n",
    "            h = 0\n",
    "            #touched = Series(np.repeat(False, l))\n",
    "            touched[:] = False\n",
    "            w += datalabels[ind] * trainingdata[ind, :]\n",
    "        if h > hs:\n",
    "            hs = h\n",
    "            ws = deepcopy(w)\n",
    "        if h == l: #stopping criterion (tried all points)\n",
    "            break\n",
    "            \n",
    "    # calculate number of correctly classified points\n",
    "    n_correct = sum([(np.dot(ws[:], trainingdata[i, :]) * datalabels[i]) >= 0 for i in range(l)])\n",
    "            \n",
    "    if (verbose):\n",
    "        print(max_iter, \"iterations were run\")\n",
    "        print(n_correct, \"points are classified correctly with current ws\")\n",
    "\n",
    "        # check if correct_s is correct:\n",
    "        #check = Series([np.dot(ws[:], trainingdata[i, :]) * datalabels[i] for i in range(l)])\n",
    "        #check_bool = (check >= 0)\n",
    "        #print(check_bool)\n",
    "        #print(check_bool.values == correct_s.values)\n",
    "        \n",
    "    return ws, n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws, n_correct = pocket_algorithm(max_iter=1000, trainingdata=trainingdata, datalabels=datalabels,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_line_pts = 2\n",
    "x=np.linspace(0, 1, num=num_line_pts)\n",
    "y=np.zeros(num_line_pts)\n",
    "for i in range(num_line_pts):\n",
    "    y[i]=(-ws[2]-ws[0]*x[i])/ws[1]\n",
    "\n",
    "index1=[i for i,e in enumerate(datalabels) if e==1]\n",
    "indexmin1=[i for i,d in enumerate(datalabels) if d==-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plt.plot(trainingdata[index1,0],trainingdata[index1,1],'ro')\n",
    "plt.plot(trainingdata[indexmin1,0],trainingdata[indexmin1,1],'b*')\n",
    "plt.plot(x,y)\n",
    "#labels = ['point{0}'.format(i) for i in range(l)]\n",
    "#for label, x_plot, y_plot in zip(labels, trainingdata[:, 0], trainingdata[:, 1]):\n",
    "#    plt.annotate(label, xy=(x_plot, y_plot))\n",
    "format_plot(fig, ax, 0, 0, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Monitor Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_iters = [10, 100, 1000]\n",
    "#max_iters = [10, 100]\n",
    "point_numbers = [10, 50, 500, 10000]\n",
    "#point_numbers = [10, 50]\n",
    "dims = [2, 3, 5, 10, 50, 200]\n",
    "#dims = [2, 3]\n",
    "num_trials = 10 # number of test datasets to generate for each scenario\n",
    "rel_wrong = 0.1 # factor, how many points are labeled wrong in test dataset\n",
    "\n",
    "monitor = np.zeros((len(max_iters), len(point_numbers), len(dims)))\n",
    "n_correct_samples = []\n",
    "\n",
    "# for every scenario...\n",
    "for ((iter_ind, max_iter), (l_ind, l), (n_ind, n)) in itertools.product(enumerate(max_iters), \n",
    "              enumerate(point_numbers), enumerate(dims)):\n",
    "    n_correct_samples = []\n",
    "    \n",
    "    # ...generate num_trials times a dataset and run the algorithm\n",
    "    for trial in range(num_trials):\n",
    "        data, labels, w, theta = generate_data(n, l, int(rel_wrong * l))\n",
    "        ws, n_correct = pocket_algorithm(max_iter=max_iter, trainingdata=data, datalabels=labels)\n",
    "        n_correct_samples.append(n_correct)\n",
    "    \n",
    "    # then remember the mean percentage of correctly classified points\n",
    "    monitor[iter_ind, l_ind, n_ind] = np.mean(n_correct_samples) / l\n",
    "\n",
    "# output the results\n",
    "for i, max_iter in enumerate(max_iters):\n",
    "    print(max_iter, \"iterations:\")\n",
    "    print(DataFrame(monitor[i, :, :]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 iterations:\n",
    "\n",
    "| dimensions | 2   | 3   | 5   | 10  | 50  | 200 |\n",
    "|------------|-----|-----|-----|-----|-----|-----|\n",
    "| num points |     |     |     |     |     |     |\n",
    "| 10         | 67% | 75% | 72% | 75% | 81% | 63% |\n",
    "| 50         | 65% | 75% | 64% | 69% | 61% | 62% |\n",
    "| 500        | 71% | 68% | 70% | 69% | 72% | 59% |\n",
    "| 10000      | 71% | 71% | 67% | 62% | 64% | 63% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100 iterations:\n",
    "| dimensions | 2   | 3   | 5   | 10  | 50   | 200  |\n",
    "|------------|-----|-----|-----|-----|------|------|\n",
    "| num points |     |     |     |     |      |      |\n",
    "| 10         | 89% | 89% | 92% | 98% | 100% | 100% |\n",
    "| 50         | 85% | 78% | 78% | 76% | 67%  | 80%  |\n",
    "| 500        | 82% | 77% | 74% | 80% | 74%  | 70%  |\n",
    "| 10000      | 78% | 76% | 74% | 63% | 71%  | 66%  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1000 iterations:\n",
    "| dimensions | 2   | 3   | 5   | 10   | 50   | 200  |\n",
    "|------------|-----|-----|-----|------|------|------|\n",
    "| num points |     |     |     |      |      |      |\n",
    "| 10         | 93% | 96% | 99% | 100% | 100% | 100% |\n",
    "| 50         | 86% | 86% | 81% | 88%  | 98%  | 100% |\n",
    "| 500        | 85% | 84% | 83% | 80%  | 74%  | 72%  |\n",
    "| 10000      | 84% | 84% | 82% | 79%  | 72%  | 75%  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
